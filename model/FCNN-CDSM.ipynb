{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7adfa90-0527-43c6-b885-3b78c9863557",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Time of Feature Extraction: 38.55 s\n",
      "Shape of adjusted miRNA features: torch.Size([444, 512])\n",
      "Shape of adjusted mRNA features: torch.Size([444, 512])\n",
      "Shape of adjusted DNA methylation features: torch.Size([444, 512])\n",
      "Shape of training features: (355, 1544)\n",
      "Shape of training labels: (355,)\n",
      "Shape of test features: (89, 1544)\n",
      "Shape of test labels: (89,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# 定义全连接层\n",
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(FullyConnected, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "# 定义1x1卷积层\n",
    "class Conv1x1(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(Conv1x1, self).__init__()\n",
    "        self.conv = nn.Conv1d(input_channels, output_channels, kernel_size=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 读取DNA甲基化数据并进行特征选择\n",
    "methy_data_list = []\n",
    "target_dim = 512\n",
    "\n",
    "for i in range(1, 23):\n",
    "    file_path = f'../data/resampled_methy_data_by_chrom/resampled_methy_data_chr{i}.csv'\n",
    "    methy_data = pd.read_csv(file_path, index_col=0)\n",
    "    \n",
    "    # 使用全连接层调整特征数\n",
    "    methy_data_tensor = torch.tensor(methy_data.values, dtype=torch.float32)\n",
    "    fc_layer = FullyConnected(methy_data_tensor.size(1), target_dim)\n",
    "    methy_data_adjusted = fc_layer(methy_data_tensor)\n",
    "    \n",
    "    methy_data_list.append(methy_data_adjusted)\n",
    "\n",
    "file_path = '../data/resampled_methy_data_by_chrom/resampled_methy_data_chrX.csv'\n",
    "methy_data_chrX = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "# 使用全连接层调整特征数\n",
    "methy_data_chrX_tensor = torch.tensor(methy_data_chrX.values, dtype=torch.float32)\n",
    "fc_layer = FullyConnected(methy_data_chrX_tensor.size(1), target_dim)\n",
    "methy_data_chrX_adjusted = fc_layer(methy_data_chrX_tensor)\n",
    "\n",
    "methy_data_list.append(methy_data_chrX_adjusted)\n",
    "\n",
    "# 将数据转换为PyTorch Tensor,使用axis=0\n",
    "methy_data_tensor = torch.stack(methy_data_list, dim=0)\n",
    "\n",
    "# 对methy_data_tensor进行维度重排,将维度调整为(batch_size, in_channels, length)\n",
    "methy_data_tensor = methy_data_tensor.permute(1, 0, 2)\n",
    "\n",
    "# 使用1x1卷积层将DNA甲基化特征转换为(444, 1024)\n",
    "conv1x1 = Conv1x1(methy_data_tensor.size(1), 1)\n",
    "methy_data_adjusted = conv1x1(methy_data_tensor)\n",
    "methy_data_adjusted = methy_data_adjusted.squeeze(1)\n",
    "\n",
    "# 读取miRNA数据并进行特征选择\n",
    "mirna_data = pd.read_csv('../data/resampled_clinical _mirna_mina_data/resampled_mirna_data_svmsmote.csv', index_col=0)\n",
    "\n",
    "# 使用全连接层调整特征数\n",
    "mirna_data_tensor = torch.tensor(mirna_data.values, dtype=torch.float32)\n",
    "fc_layer_mirna = FullyConnected(mirna_data_tensor.size(1), target_dim)\n",
    "mirna_data_adjusted = fc_layer_mirna(mirna_data_tensor)\n",
    "\n",
    "# 读取mRNA数据并进行特征选择\n",
    "mrna_data = pd.read_csv('../data/resampled_clinical _mirna_mina_data/resampled_mrna_data_svmsmote.csv', index_col=0)\n",
    "\n",
    "# 使用全连接层调整特征数\n",
    "mrna_data_tensor = torch.tensor(mrna_data.values, dtype=torch.float32)\n",
    "fc_layer_mrna = FullyConnected(mrna_data_tensor.size(1), target_dim)\n",
    "mrna_data_adjusted = fc_layer_mrna(mrna_data_tensor)\n",
    "\n",
    "end_time = time.time()\n",
    "feature_extraction_time = end_time - start_time\n",
    "\n",
    "print(f\"Common Time of Feature Extraction: {feature_extraction_time:.2f} s\")\n",
    "\n",
    "# 打印调整后的miRNA、mRNA和DNA甲基化特征形状\n",
    "print(f\"Shape of adjusted miRNA features: {mirna_data_adjusted.shape}\")\n",
    "print(f\"Shape of adjusted mRNA features: {mrna_data_adjusted.shape}\")\n",
    "print(f\"Shape of adjusted DNA methylation features: {methy_data_adjusted.shape}\")\n",
    "\n",
    "# 将Tensor转换为NumPy数组\n",
    "mirna_array = mirna_data_adjusted.detach().numpy()\n",
    "mrna_array = mrna_data_adjusted.detach().numpy()\n",
    "methy_array = methy_data_adjusted.detach().numpy()\n",
    "\n",
    "# 创建样本ID列表\n",
    "sample_ids = [f\"sample{i+1}\" for i in range(mirna_array.shape[0])]\n",
    "\n",
    "# 将NumPy数组转换为DataFrame\n",
    "mirna_df = pd.DataFrame(mirna_array, index=sample_ids)\n",
    "mrna_df = pd.DataFrame(mrna_array, index=sample_ids)\n",
    "methy_df = pd.DataFrame(methy_array, index=sample_ids)\n",
    "\n",
    "# 连接三个DataFrame\n",
    "combined_df = pd.concat([mirna_df, mrna_df, methy_df], axis=1)\n",
    "\n",
    "# 重新生成列名\n",
    "num_mirna_features = mirna_df.shape[1]\n",
    "num_mrna_features = mrna_df.shape[1]\n",
    "num_methy_features = methy_df.shape[1]\n",
    "\n",
    "mirna_columns = [f\"mirna_{i}\" for i in range(num_mirna_features)]\n",
    "mrna_columns = [f\"mrna_{i}\" for i in range(num_mrna_features)]\n",
    "methy_columns = [f\"methy_{i}\" for i in range(num_methy_features)]\n",
    "\n",
    "combined_columns = mirna_columns + mrna_columns + methy_columns\n",
    "combined_df.columns = combined_columns\n",
    "\n",
    "# 读取临床数据\n",
    "clinical_data = pd.read_csv('../data/resampled_clinical _mirna_mina_data/resampled_clinical_data_svmsmote.csv', low_memory=False, index_col=0)\n",
    "\n",
    "# 根据样本ID将临床数据与合并后的特征数据对齐\n",
    "aligned_data = pd.concat([clinical_data, combined_df], axis=1, join='inner')\n",
    "\n",
    "# 提取特征和标签\n",
    "X = aligned_data.drop('tumor_stage.diagnoses', axis=1)\n",
    "y = aligned_data['tumor_stage.diagnoses']\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 打印训练集和测试集的形状\n",
    "print(f\"Shape of training features: {X_train.shape}\")\n",
    "print(f\"Shape of training labels: {y_train.shape}\")\n",
    "print(f\"Shape of test features: {X_test.shape}\")\n",
    "print(f\"Shape of test labels: {y_test.shape}\")\n",
    "\n",
    "# 将 DataFrame 转换为 NumPy 数组\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e436840a-d761-46bc-a898-ef900b154529",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68a5c20e-360f-4114-ba7e-747f8d542965",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'metric': 'euclidean', 'n_neighbors': 5, 'p': 1}\n",
      "Best cross-validation score: 0.698161389172625\n",
      "\n",
      "Accuracy: 0.8198\n",
      "Precision (Macro): 0.8383\n",
      "Precision (Micro): 0.8198\n",
      "Recall (Macro): 0.8227\n",
      "Recall (Micro): 0.8198\n",
      "F1-score (Macro): 0.8273\n",
      "F1-score (Micro): 0.8198\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 64  12   2   0   0]\n",
      " [ 14 101   3   0   0]\n",
      " [  4  14  78   7   0]\n",
      " [  0   6  18  51   0]\n",
      " [  0   0   0   0  70]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 定义KNN分类器的超参数网格\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "# 创建KNN分类器\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "# 使用网格搜索和分层交叉验证优化超参数\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(knn_classifier, param_grid, cv=cv, scoring='accuracy')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# 打印最佳超参数和评估分数\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
    "\n",
    "# 使用最佳超参数重新训练KNN分类器\n",
    "best_knn_classifier = grid_search.best_estimator_\n",
    "\n",
    "# 在整个数据集上进行预测\n",
    "y_pred = best_knn_classifier.predict(X)\n",
    "\n",
    "# 计算评估指标\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision_macro = precision_score(y, y_pred, average='macro')\n",
    "precision_micro = precision_score(y, y_pred, average='micro')\n",
    "recall_macro = recall_score(y, y_pred, average='macro')\n",
    "recall_micro = recall_score(y, y_pred, average='micro')\n",
    "f1_macro = f1_score(y, y_pred, average='macro')\n",
    "f1_micro = f1_score(y, y_pred, average='micro')\n",
    "\n",
    "# 打印评估指标\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "print(f\"Precision (Micro): {precision_micro:.4f}\")\n",
    "print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "print(f\"Recall (Micro): {recall_micro:.4f}\")\n",
    "print(f\"F1-score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"F1-score (Micro): {f1_micro:.4f}\")\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa9f32d-31f1-444f-af17-06b577d33212",
   "metadata": {},
   "source": [
    "# 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8efffab8-b686-4854-a692-c06bbc7e3d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9932\n",
      "Precision (Macro): 0.9945\n",
      "Precision (Micro): 0.9932\n",
      "Recall (Macro): 0.9920\n",
      "Recall (Micro): 0.9932\n",
      "F1-score (Macro): 0.9932\n",
      "F1-score (Micro): 0.9932\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 78   0   0   0   0]\n",
      " [  0 118   0   0   0]\n",
      " [  0   0 103   0   0]\n",
      " [  0   1   2  72   0]\n",
      " [  0   0   0   0  70]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 创建随机森林分类器并设置参数\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=8, min_samples_split=5, min_samples_leaf=2, random_state=42)\n",
    "\n",
    "# 训练随机森林分类器\n",
    "rf_classifier.fit(X, y)\n",
    "\n",
    "# 在整个数据集上进行预测\n",
    "y_pred = rf_classifier.predict(X)\n",
    "\n",
    "# 计算评估指标\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision_macro = precision_score(y, y_pred, average='macro')\n",
    "precision_micro = precision_score(y, y_pred, average='micro')\n",
    "recall_macro = recall_score(y, y_pred, average='macro')\n",
    "recall_micro = recall_score(y, y_pred, average='micro')\n",
    "f1_macro = f1_score(y, y_pred, average='macro')\n",
    "f1_micro = f1_score(y, y_pred, average='micro')\n",
    "\n",
    "# 打印评估指标\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "print(f\"Precision (Micro): {precision_micro:.4f}\")\n",
    "print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "print(f\"Recall (Micro): {recall_micro:.4f}\")\n",
    "print(f\"F1-score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"F1-score (Micro): {f1_micro:.4f}\")\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e32c576-2b97-4a58-a17c-0b62b490f9ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "# XGBooost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e274ceb-12c1-41d0-8df1-095cdb0964a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9617\n",
      "Precision (Macro): 0.9699\n",
      "Precision (Micro): 0.9617\n",
      "Recall (Macro): 0.9554\n",
      "Recall (Micro): 0.9617\n",
      "F1-score (Macro): 0.9596\n",
      "F1-score (Micro): 0.9617\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 78   0   0   0   0]\n",
      " [  0 118   0   0   0]\n",
      " [  1   0 102   0   0]\n",
      " [  0   5  11  59   0]\n",
      " [  0   0   0   0  70]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 创建XGBoost分类器并设置参数\n",
    "xgb_classifier = XGBClassifier(n_estimators=100, max_depth=1, min_child_weight=5, subsample=0.8, colsample_bytree=0.8, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# 训练XGBoost分类器\n",
    "xgb_classifier.fit(X, y)\n",
    "\n",
    "# 在整个数据集上进行预测\n",
    "y_pred = xgb_classifier.predict(X)\n",
    "\n",
    "# 计算评估指标\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision_macro = precision_score(y, y_pred, average='macro')\n",
    "precision_micro = precision_score(y, y_pred, average='micro')\n",
    "recall_macro = recall_score(y, y_pred, average='macro')\n",
    "recall_micro = recall_score(y, y_pred, average='micro')\n",
    "f1_macro = f1_score(y, y_pred, average='macro')\n",
    "f1_micro = f1_score(y, y_pred, average='micro')\n",
    "\n",
    "# 打印评估指标\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "print(f\"Precision (Micro): {precision_micro:.4f}\")\n",
    "print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "print(f\"Recall (Micro): {recall_micro:.4f}\")\n",
    "print(f\"F1-score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"F1-score (Micro): {f1_micro:.4f}\")\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c143a4-fa3e-41bd-be1c-bf14b4eee27c",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ef4027d-2238-4e6f-9af4-a4ff87d21b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9640\n",
      "Precision (Macro): 0.9726\n",
      "Precision (Micro): 0.9640\n",
      "Recall (Macro): 0.9573\n",
      "Recall (Micro): 0.9640\n",
      "F1-score (Macro): 0.9618\n",
      "F1-score (Micro): 0.9640\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 78   0   0   0   0]\n",
      " [  0 118   0   0   0]\n",
      " [  0   0 103   0   0]\n",
      " [  0   5  11  59   0]\n",
      " [  0   0   0   0  70]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# 创建CatBoost分类器并设置参数\n",
    "cat_classifier = CatBoostClassifier(iterations=300, depth=1, learning_rate=0.1, loss_function='MultiClass', random_seed=42,verbose=False)\n",
    "\n",
    "# 训练CatBoost分类器\n",
    "cat_classifier.fit(X, y)\n",
    "\n",
    "# 在整个数据集上进行预测\n",
    "y_pred = cat_classifier.predict(X)\n",
    "\n",
    "# 计算评估指标\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision_macro = precision_score(y, y_pred, average='macro')\n",
    "precision_micro = precision_score(y, y_pred, average='micro')\n",
    "recall_macro = recall_score(y, y_pred, average='macro')\n",
    "recall_micro = recall_score(y, y_pred, average='micro')\n",
    "f1_macro = f1_score(y, y_pred, average='macro')\n",
    "f1_micro = f1_score(y, y_pred, average='micro')\n",
    "\n",
    "# 打印评估指标\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "print(f\"Precision (Micro): {precision_micro:.4f}\")\n",
    "print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "print(f\"Recall (Micro): {recall_micro:.4f}\")\n",
    "print(f\"F1-score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"F1-score (Micro): {f1_micro:.4f}\")\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1f1135-83bd-4582-bce5-18acb02d7b64",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e98f438-3572-4b2b-bfe6-9771bd437bbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.8559\n",
      "Precision (Macro): 0.9116\n",
      "Precision (Micro): 0.8559\n",
      "Recall (Macro): 0.8327\n",
      "Recall (Micro): 0.8559\n",
      "F1-score (Macro): 0.8444\n",
      "F1-score (Micro): 0.8559\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 45  33   0   0   0]\n",
      " [  0 118   0   0   0]\n",
      " [  0   0 103   0   0]\n",
      " [  0   7  24  44   0]\n",
      " [  0   0   0   0  70]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 创建SVM分类器并设置参数\n",
    "svm_classifier = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "\n",
    "# 训练SVM分类器\n",
    "svm_classifier.fit(X, y)\n",
    "\n",
    "# 在整个数据集上进行预测\n",
    "y_pred = svm_classifier.predict(X)\n",
    "\n",
    "# 计算评估指标\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision_macro = precision_score(y, y_pred, average='macro')\n",
    "precision_micro = precision_score(y, y_pred, average='micro')\n",
    "recall_macro = recall_score(y, y_pred, average='macro')\n",
    "recall_micro = recall_score(y, y_pred, average='micro')\n",
    "f1_macro = f1_score(y, y_pred, average='macro')\n",
    "f1_micro = f1_score(y, y_pred, average='micro')\n",
    "\n",
    "# 打印评估指标\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "print(f\"Precision (Micro): {precision_micro:.4f}\")\n",
    "print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "print(f\"Recall (Micro): {recall_micro:.4f}\")\n",
    "print(f\"F1-score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"F1-score (Micro): {f1_micro:.4f}\")\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86c6477-9fec-40f6-a1a0-8ca5a9f11e5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc77e454-4d75-4cb3-ace8-8ebb443275ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step\n",
      "\n",
      "Accuracy: 0.7191\n",
      "Precision (Macro): 0.7233\n",
      "Precision (Micro): 0.7191\n",
      "Recall (Macro): 0.7152\n",
      "Recall (Micro): 0.7191\n",
      "F1-score (Macro): 0.7117\n",
      "F1-score (Micro): 0.7191\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9  3  0  0  0]\n",
      " [ 1 17  4  2  0]\n",
      " [ 2  1 12  2  0]\n",
      " [ 0  3  7  7  0]\n",
      " [ 0  0  0  0 19]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "# 创建神经网络模型\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(len(set(y)), activation='softmax')\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=32, validation_split=0.1, verbose=0)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "\n",
    "# 计算评估指标\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision_macro = precision_score(y_test, y_pred, average='macro')\n",
    "precision_micro = precision_score(y_test, y_pred, average='micro') \n",
    "recall_macro = recall_score(y_test, y_pred, average='macro')\n",
    "recall_micro = recall_score(y_test, y_pred, average='micro')\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro') \n",
    "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "# 打印评估指标\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (Macro): {precision_macro:.4f}\") \n",
    "print(f\"Precision (Micro): {precision_micro:.4f}\")\n",
    "print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "print(f\"Recall (Micro): {recall_micro:.4f}\") \n",
    "print(f\"F1-score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"F1-score (Micro): {f1_micro:.4f}\")\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eb990a-b0dc-40bb-a546-6cff6b7805e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78b37d33-e48c-45a2-8da4-71bc9db011f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 7ms/step\n",
      "\n",
      "Accuracy: 0.6404\n",
      "Precision (Macro): 0.6694\n",
      "Precision (Micro): 0.6404\n",
      "Recall (Macro): 0.6515\n",
      "Recall (Micro): 0.6404\n",
      "F1-score (Macro): 0.6484\n",
      "F1-score (Micro): 0.6404\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  1  1  0  0]\n",
      " [ 1 13  7  3  0]\n",
      " [ 2  6  9  0  0]\n",
      " [ 0  5  6  6  0]\n",
      " [ 0  0  0  0 19]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
    "\n",
    "# 调整输入数据的形状以适应 CNN\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# 创建 CNN 模型\n",
    "model = Sequential([\n",
    "    Conv1D(64, 3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    MaxPooling1D(2),\n",
    "    Conv1D(128, 3, activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(set(y)), activation='softmax')\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=0)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "\n",
    "# 计算评估指标\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision_macro = precision_score(y_test, y_pred, average='macro')\n",
    "precision_micro = precision_score(y_test, y_pred, average='micro') \n",
    "recall_macro = recall_score(y_test, y_pred, average='macro')\n",
    "recall_micro = recall_score(y_test, y_pred, average='micro')\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro') \n",
    "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "# 打印评估指标\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (Macro): {precision_macro:.4f}\") \n",
    "print(f\"Precision (Micro): {precision_micro:.4f}\")\n",
    "print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "print(f\"Recall (Micro): {recall_micro:.4f}\") \n",
    "print(f\"F1-score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"F1-score (Micro): {f1_micro:.4f}\")\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
