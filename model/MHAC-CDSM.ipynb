{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e35ca035-261f-450d-ac62-ee173c5da8d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([23, 444, 512])\n",
      "Output shape after conv: torch.Size([1, 444, 512])\n",
      "Output shape after squeeze: torch.Size([444, 512])\n",
      "Common Time of Feature Extraction: 52.12 s\n",
      "Shape of adjusted miRNA features: torch.Size([444, 512])\n",
      "Shape of adjusted mRNA features: torch.Size([444, 512])\n",
      "Shape of training features: (355, 1544)\n",
      "Shape of training labels: (355,)\n",
      "Shape of test features: (89, 1544)\n",
      "Shape of test labels: (89,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# 定义自注意力层\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.query = nn.Linear(input_dim, output_dim)\n",
    "        self.key = nn.Linear(input_dim, output_dim)\n",
    "        self.value = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        v = self.value(x)\n",
    "\n",
    "        attention_scores = torch.matmul(q, k.transpose(-2, -1))\n",
    "        attention_scores = attention_scores / (k.size(-1) ** 0.5)\n",
    "        attention_weights = torch.softmax(attention_scores, dim=-1)\n",
    "\n",
    "        output = torch.matmul(attention_weights, v)\n",
    "        return output\n",
    "\n",
    "# 定义多头注意力层\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, output_dim):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_heads = nn.ModuleList([\n",
    "            SelfAttention(input_dim, output_dim // num_heads)\n",
    "            for _ in range(num_heads)\n",
    "        ])\n",
    "        self.output_layer = nn.Linear(output_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention_outputs = [head(x) for head in self.attention_heads]\n",
    "        concat_output = torch.cat(attention_outputs, dim=-1)\n",
    "        output = self.output_layer(concat_output)\n",
    "        return output\n",
    "        \n",
    "# 特征提取器\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f\"Input shape: {x.shape}\")\n",
    "        x = self.conv(x)\n",
    "        print(f\"Output shape after conv: {x.shape}\")\n",
    "        x = x.squeeze(0)\n",
    "        print(f\"Output shape after squeeze: {x.shape}\")\n",
    "        return x\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 读取DNA甲基化数据并进行特征选择\n",
    "methy_data_list = []\n",
    "target_dim = 512\n",
    "num_heads = 8\n",
    "\n",
    "for i in range(1, 23):\n",
    "    file_path = f'../data/resampled_methy_data_by_chrom/resampled_methy_data_chr{i}.csv'\n",
    "    methy_data = pd.read_csv(file_path, index_col=0)\n",
    "    \n",
    "    # 使用多头注意力层调整特征数\n",
    "    methy_data_tensor = torch.tensor(methy_data.values, dtype=torch.float32)\n",
    "    attention_layer = MultiHeadAttention(methy_data_tensor.size(1), num_heads, target_dim)\n",
    "    methy_data_adjusted = attention_layer(methy_data_tensor)\n",
    "    \n",
    "    methy_data_list.append(methy_data_adjusted.detach().numpy())\n",
    "\n",
    "file_path = '../data/resampled_methy_data_by_chrom/resampled_methy_data_chrX.csv'\n",
    "methy_data_chrX = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "# 使用多头注意力层调整特征数\n",
    "methy_data_chrX_tensor = torch.tensor(methy_data_chrX.values, dtype=torch.float32)\n",
    "attention_layer = MultiHeadAttention(methy_data_chrX_tensor.size(1), num_heads, target_dim)\n",
    "methy_data_chrX_adjusted = attention_layer(methy_data_chrX_tensor)\n",
    "\n",
    "methy_data_list.append(methy_data_chrX_adjusted.detach().numpy())\n",
    "\n",
    "# 将数据转换为PyTorch Tensor,使用axis=0\n",
    "methy_data_tensor = torch.tensor(np.stack(methy_data_list, axis=0), dtype=torch.float32)\n",
    "\n",
    "# 创建特征提取器实例\n",
    "feature_extractor = FeatureExtractor(in_channels=23)\n",
    "\n",
    "# 将特征张量传递给特征提取器\n",
    "compressed_methy_features = feature_extractor(methy_data_tensor)\n",
    "\n",
    "# 读取miRNA数据并进行特征选择\n",
    "mirna_data = pd.read_csv('../data/resampled_clinical _mirna_mina_data/resampled_mirna_data_svmsmote.csv', index_col=0)\n",
    "\n",
    "# 使用多头注意力层调整特征数\n",
    "mirna_data_tensor = torch.tensor(mirna_data.values, dtype=torch.float32)\n",
    "attention_layer_mirna = MultiHeadAttention(mirna_data_tensor.size(1), num_heads, target_dim)\n",
    "mirna_data_adjusted = attention_layer_mirna(mirna_data_tensor)\n",
    "\n",
    "# 读取mRNA数据并进行特征选择\n",
    "mrna_data = pd.read_csv('../data/resampled_clinical _mirna_mina_data/resampled_mrna_data_svmsmote.csv', index_col=0)\n",
    "\n",
    "# 使用多头注意力层调整特征数\n",
    "mrna_data_tensor = torch.tensor(mrna_data.values, dtype=torch.float32)\n",
    "attention_layer_mrna = MultiHeadAttention(mrna_data_tensor.size(1), num_heads, target_dim)\n",
    "mrna_data_adjusted = attention_layer_mrna(mrna_data_tensor)\n",
    "\n",
    "end_time = time.time()\n",
    "feature_extraction_time = end_time - start_time\n",
    "\n",
    "print(f\"Common Time of Feature Extraction: {feature_extraction_time:.2f} s\")\n",
    "\n",
    "# 打印调整后的miRNA和mRNA特征形状\n",
    "print(f\"Shape of adjusted miRNA features: {mirna_data_adjusted.shape}\")\n",
    "print(f\"Shape of adjusted mRNA features: {mrna_data_adjusted.shape}\")\n",
    "\n",
    "# 将Tensor转换为NumPy数组\n",
    "mirna_array = mirna_data_adjusted.detach().numpy()\n",
    "mrna_array = mrna_data_adjusted.detach().numpy()\n",
    "methy_array = compressed_methy_features.detach().numpy()\n",
    "\n",
    "# 创建样本ID列表\n",
    "sample_ids = [f\"sample{i+1}\" for i in range(mirna_array.shape[0])]\n",
    "\n",
    "# 将NumPy数组转换为DataFrame\n",
    "mirna_df = pd.DataFrame(mirna_array, index=sample_ids)\n",
    "mrna_df = pd.DataFrame(mrna_array, index=sample_ids)\n",
    "methy_df = pd.DataFrame(methy_array, index=sample_ids)\n",
    "\n",
    "# 连接三个DataFrame\n",
    "combined_df = pd.concat([mirna_df, mrna_df, methy_df], axis=1)\n",
    "\n",
    "# 重新生成列名\n",
    "num_mirna_features = mirna_df.shape[1]\n",
    "num_mrna_features = mrna_df.shape[1]\n",
    "num_methy_features = methy_df.shape[1]\n",
    "\n",
    "mirna_columns = [f\"mirna_{i}\" for i in range(num_mirna_features)]\n",
    "mrna_columns = [f\"mrna_{i}\" for i in range(num_mrna_features)]\n",
    "methy_columns = [f\"methy_{i}\" for i in range(num_methy_features)]\n",
    "\n",
    "combined_columns = mirna_columns + mrna_columns + methy_columns\n",
    "combined_df.columns = combined_columns\n",
    "\n",
    "# 读取临床数据\n",
    "clinical_data = pd.read_csv('../data/resampled_clinical _mirna_mina_data/resampled_clinical_data_svmsmote.csv', low_memory=False, index_col=0)\n",
    "\n",
    "# 根据样本ID将临床数据与合并后的特征数据对齐\n",
    "aligned_data = pd.concat([clinical_data, combined_df], axis=1, join='inner')\n",
    "\n",
    "# 提取特征和标签\n",
    "X = aligned_data.drop('tumor_stage.diagnoses', axis=1)\n",
    "y = aligned_data['tumor_stage.diagnoses']\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 打印训练集和测试集的形状\n",
    "print(f\"Shape of training features: {X_train.shape}\")\n",
    "print(f\"Shape of training labels: {y_train.shape}\")\n",
    "print(f\"Shape of test features: {X_test.shape}\")\n",
    "print(f\"Shape of test labels: {y_test.shape}\")\n",
    "\n",
    "# 将 DataFrame 转换为 NumPy 数组\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b8b14b-481f-4268-b869-94a75628809a",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3af1717-d4d3-4f35-ade3-ae68bd2c0a2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'p': 1}\n",
      "Best cross-validation score: 0.8784984678243106\n",
      "\n",
      "Accuracy: 0.9459\n",
      "Precision (Macro): 0.9452\n",
      "Precision (Micro): 0.9459\n",
      "Recall (Macro): 0.9449\n",
      "Recall (Micro): 0.9459\n",
      "F1-score (Macro): 0.9450\n",
      "F1-score (Micro): 0.9459\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 78   0   0   0   0]\n",
      " [  0 117   0   1   0]\n",
      " [  0   0  92  11   0]\n",
      " [  0   3   9  63   0]\n",
      " [  0   0   0   0  70]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 定义KNN分类器的超参数网格\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "# 创建KNN分类器\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "# 使用网格搜索和分层交叉验证优化超参数\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(knn_classifier, param_grid, cv=cv, scoring='accuracy')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# 打印最佳超参数和评估分数\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
    "\n",
    "# 使用最佳超参数重新训练KNN分类器\n",
    "best_knn_classifier = grid_search.best_estimator_\n",
    "\n",
    "# 在整个数据集上进行预测\n",
    "y_pred = best_knn_classifier.predict(X)\n",
    "\n",
    "# 计算评估指标\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision_macro = precision_score(y, y_pred, average='macro')\n",
    "precision_micro = precision_score(y, y_pred, average='micro')\n",
    "recall_macro = recall_score(y, y_pred, average='macro')\n",
    "recall_micro = recall_score(y, y_pred, average='micro')\n",
    "f1_macro = f1_score(y, y_pred, average='macro')\n",
    "f1_micro = f1_score(y, y_pred, average='micro')\n",
    "\n",
    "# 打印评估指标\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "print(f\"Precision (Micro): {precision_micro:.4f}\")\n",
    "print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "print(f\"Recall (Micro): {recall_micro:.4f}\")\n",
    "print(f\"F1-score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"F1-score (Micro): {f1_micro:.4f}\")\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a468d86e-1998-4c9d-954b-bdec0a08b063",
   "metadata": {},
   "source": [
    "# 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da495973-8dc2-47ad-a19e-a5684f3e9c1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9955\n",
      "Precision (Macro): 0.9964\n",
      "Precision (Micro): 0.9955\n",
      "Recall (Macro): 0.9947\n",
      "Recall (Micro): 0.9955\n",
      "F1-score (Macro): 0.9955\n",
      "F1-score (Micro): 0.9955\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 78   0   0   0   0]\n",
      " [  0 118   0   0   0]\n",
      " [  0   0 103   0   0]\n",
      " [  0   1   1  73   0]\n",
      " [  0   0   0   0  70]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 创建随机森林分类器并设置参数\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=8, min_samples_split=5, min_samples_leaf=2, random_state=42)\n",
    "\n",
    "# 训练随机森林分类器\n",
    "rf_classifier.fit(X, y)\n",
    "\n",
    "# 在整个数据集上进行预测\n",
    "y_pred = rf_classifier.predict(X)\n",
    "\n",
    "# 计算评估指标\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision_macro = precision_score(y, y_pred, average='macro')\n",
    "precision_micro = precision_score(y, y_pred, average='micro')\n",
    "recall_macro = recall_score(y, y_pred, average='macro')\n",
    "recall_micro = recall_score(y, y_pred, average='micro')\n",
    "f1_macro = f1_score(y, y_pred, average='macro')\n",
    "f1_micro = f1_score(y, y_pred, average='micro')\n",
    "\n",
    "# 打印评估指标\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "print(f\"Precision (Micro): {precision_micro:.4f}\")\n",
    "print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "print(f\"Recall (Micro): {recall_micro:.4f}\")\n",
    "print(f\"F1-score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"F1-score (Micro): {f1_micro:.4f}\")\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33abfb4-abbe-4bec-9eb2-cd10107b7c9d",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90643b94-edea-489a-9fcf-19d397e43f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9730\n",
      "Precision (Macro): 0.9790\n",
      "Precision (Micro): 0.9730\n",
      "Recall (Macro): 0.9680\n",
      "Recall (Micro): 0.9730\n",
      "F1-score (Macro): 0.9718\n",
      "F1-score (Micro): 0.9730\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 78   0   0   0   0]\n",
      " [  0 118   0   0   0]\n",
      " [  0   0 103   0   0]\n",
      " [  0   4   8  63   0]\n",
      " [  0   0   0   0  70]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 创建XGBoost分类器并设置参数\n",
    "xgb_classifier = XGBClassifier(n_estimators=100, max_depth=1, min_child_weight=5, subsample=0.8, colsample_bytree=0.8, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# 训练XGBoost分类器\n",
    "xgb_classifier.fit(X, y)\n",
    "\n",
    "# 在整个数据集上进行预测\n",
    "y_pred = xgb_classifier.predict(X)\n",
    "\n",
    "# 计算评估指标\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision_macro = precision_score(y, y_pred, average='macro')\n",
    "precision_micro = precision_score(y, y_pred, average='micro')\n",
    "recall_macro = recall_score(y, y_pred, average='macro')\n",
    "recall_micro = recall_score(y, y_pred, average='micro')\n",
    "f1_macro = f1_score(y, y_pred, average='macro')\n",
    "f1_micro = f1_score(y, y_pred, average='micro')\n",
    "\n",
    "# 打印评估指标\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "print(f\"Precision (Micro): {precision_micro:.4f}\")\n",
    "print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "print(f\"Recall (Micro): {recall_micro:.4f}\")\n",
    "print(f\"F1-score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"F1-score (Micro): {f1_micro:.4f}\")\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a11b76-b5cb-4ab6-bcda-cb31d7c8f996",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04902069-f95d-4991-b484-dffeda3b1bc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9685\n",
      "Precision (Macro): 0.9757\n",
      "Precision (Micro): 0.9685\n",
      "Recall (Macro): 0.9627\n",
      "Recall (Micro): 0.9685\n",
      "F1-score (Macro): 0.9668\n",
      "F1-score (Micro): 0.9685\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 78   0   0   0   0]\n",
      " [  0 118   0   0   0]\n",
      " [  0   0 103   0   0]\n",
      " [  0   4  10  61   0]\n",
      " [  0   0   0   0  70]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# 创建CatBoost分类器并设置参数\n",
    "cat_classifier = CatBoostClassifier(iterations=300, depth=1, learning_rate=0.1, loss_function='MultiClass', random_seed=42,verbose=False)\n",
    "\n",
    "# 训练CatBoost分类器\n",
    "cat_classifier.fit(X, y)\n",
    "\n",
    "# 在整个数据集上进行预测\n",
    "y_pred = cat_classifier.predict(X)\n",
    "\n",
    "# 计算评估指标\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision_macro = precision_score(y, y_pred, average='macro')\n",
    "precision_micro = precision_score(y, y_pred, average='micro')\n",
    "recall_macro = recall_score(y, y_pred, average='macro')\n",
    "recall_micro = recall_score(y, y_pred, average='micro')\n",
    "f1_macro = f1_score(y, y_pred, average='macro')\n",
    "f1_micro = f1_score(y, y_pred, average='micro')\n",
    "\n",
    "# 打印评估指标\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "print(f\"Precision (Micro): {precision_micro:.4f}\")\n",
    "print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "print(f\"Recall (Micro): {recall_micro:.4f}\")\n",
    "print(f\"F1-score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"F1-score (Micro): {f1_micro:.4f}\")\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d60035d-793b-4f81-b3bc-ae77753e855f",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb8690fa-5389-4970-a1d2-e9e6d157d969",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.6959\n",
      "Precision (Macro): 0.7662\n",
      "Precision (Micro): 0.6959\n",
      "Recall (Macro): 0.6606\n",
      "Recall (Micro): 0.6959\n",
      "F1-score (Macro): 0.6300\n",
      "F1-score (Micro): 0.6959\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  7  71   0   0   0]\n",
      " [  0 117   0   0   1]\n",
      " [  1   2  86  14   0]\n",
      " [  0  12  34  29   0]\n",
      " [  0   0   0   0  70]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 创建SVM分类器并设置参数\n",
    "svm_classifier = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "\n",
    "# 训练SVM分类器\n",
    "svm_classifier.fit(X, y)\n",
    "\n",
    "# 在整个数据集上进行预测\n",
    "y_pred = svm_classifier.predict(X)\n",
    "\n",
    "# 计算评估指标\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision_macro = precision_score(y, y_pred, average='macro')\n",
    "precision_micro = precision_score(y, y_pred, average='micro')\n",
    "recall_macro = recall_score(y, y_pred, average='macro')\n",
    "recall_micro = recall_score(y, y_pred, average='micro')\n",
    "f1_macro = f1_score(y, y_pred, average='macro')\n",
    "f1_micro = f1_score(y, y_pred, average='micro')\n",
    "\n",
    "# 打印评估指标\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "print(f\"Precision (Micro): {precision_micro:.4f}\")\n",
    "print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "print(f\"Recall (Micro): {recall_micro:.4f}\")\n",
    "print(f\"F1-score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"F1-score (Micro): {f1_micro:.4f}\")\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade7535-5726-41d1-bcdf-7763ce3bfb5d",
   "metadata": {},
   "source": [
    "# NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d44a5bb5-b0d2-4e46-80ac-e9ed89c95dd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step\n",
      "\n",
      "Accuracy: 0.8539\n",
      "Precision (Macro): 0.8544\n",
      "Precision (Micro): 0.8539\n",
      "Recall (Macro): 0.8505\n",
      "Recall (Micro): 0.8539\n",
      "F1-score (Macro): 0.8506\n",
      "F1-score (Micro): 0.8539\n",
      "\n",
      "Confusion Matrix:\n",
      "[[12  0  0  0  0]\n",
      " [ 0 23  1  0  0]\n",
      " [ 0  1 12  4  0]\n",
      " [ 0  3  4 10  0]\n",
      " [ 0  0  0  0 19]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "# 创建神经网络模型\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(len(set(y)), activation='softmax')\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=32, validation_split=0.1, verbose=0)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "\n",
    "# 计算评估指标\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision_macro = precision_score(y_test, y_pred, average='macro')\n",
    "precision_micro = precision_score(y_test, y_pred, average='micro') \n",
    "recall_macro = recall_score(y_test, y_pred, average='macro')\n",
    "recall_micro = recall_score(y_test, y_pred, average='micro')\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro') \n",
    "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "# 打印评估指标\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (Macro): {precision_macro:.4f}\") \n",
    "print(f\"Precision (Micro): {precision_micro:.4f}\")\n",
    "print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "print(f\"Recall (Micro): {recall_micro:.4f}\") \n",
    "print(f\"F1-score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"F1-score (Micro): {f1_micro:.4f}\")\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2347ad12-4f98-4347-bb55-0f5293c44f69",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb447bb1-ab4f-4c28-bc1e-4acca0e717f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "\n",
      "Accuracy: 0.8315\n",
      "Precision (Macro): 0.8270\n",
      "Precision (Micro): 0.8315\n",
      "Recall (Macro): 0.8235\n",
      "Recall (Micro): 0.8315\n",
      "F1-score (Macro): 0.8036\n",
      "F1-score (Micro): 0.8315\n",
      "\n",
      "Confusion Matrix:\n",
      "[[12  0  0  0  0]\n",
      " [ 0 24  0  0  0]\n",
      " [ 1  0 14  2  0]\n",
      " [ 0  3  9  5  0]\n",
      " [ 0  0  0  0 19]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
    "\n",
    "\n",
    "# 调整输入数据的形状以适应 CNN\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# 创建 CNN 模型\n",
    "model = Sequential([\n",
    "    Conv1D(64, 3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    MaxPooling1D(2),\n",
    "    Conv1D(128, 3, activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(set(y)), activation='softmax')\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=0)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "\n",
    "# 计算评估指标\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision_macro = precision_score(y_test, y_pred, average='macro')\n",
    "precision_micro = precision_score(y_test, y_pred, average='micro') \n",
    "recall_macro = recall_score(y_test, y_pred, average='macro')\n",
    "recall_micro = recall_score(y_test, y_pred, average='micro')\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro') \n",
    "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "# 打印评估指标\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (Macro): {precision_macro:.4f}\") \n",
    "print(f\"Precision (Micro): {precision_micro:.4f}\")\n",
    "print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "print(f\"Recall (Micro): {recall_micro:.4f}\") \n",
    "print(f\"F1-score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"F1-score (Micro): {f1_micro:.4f}\")\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
